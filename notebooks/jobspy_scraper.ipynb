{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc95255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jobspy import scrape_jobs\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16c6ae77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting California scrape...\n",
      "Time: 2025-11-17 00:56:31.444632\n",
      "\n",
      " California: 200 jobs scraped\n",
      "Jobs by site:\n",
      "site\n",
      "indeed    200\n",
      "Name: count, dtype: int64\n",
      "Completed at: 2025-11-17 00:56:33.297978\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: California Scrape\n",
    "print(\"Starting California scrape...\")\n",
    "print(f\"Time: {datetime.now()}\")\n",
    "\n",
    "ca_jobs = scrape_jobs(\n",
    "    site_name=[\"indeed\"],\n",
    "    search_term=\"data analyst\",\n",
    "    location=\"California\",\n",
    "    results_wanted=200,\n",
    "    country_indeed='USA',\n",
    "    enforce_annual_salary=True,\n",
    "    description_format=\"html\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "ca_jobs['state'] = 'California'\n",
    "ca_jobs.to_csv('../data/california_jobs.csv', index=False)\n",
    "print(f\"\\n California: {len(ca_jobs)} jobs scraped\")\n",
    "print(f\"Jobs by site:\\n{ca_jobs['site'].value_counts()}\")\n",
    "print(f\"Completed at: {datetime.now()}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f3a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting New York scrape...\n",
      "Time: 2025-11-17 00:57:05.219843\n",
      "\n",
      "âœ… New York: 300 jobs scraped\n",
      "Completed at: 2025-11-17 00:57:07.458177\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: New York Scrape (Indeed Only)\n",
    "print(\"Starting New York scrape...\")\n",
    "print(f\"Time: {datetime.now()}\")\n",
    "\n",
    "ny_jobs = scrape_jobs(\n",
    "    site_name=[\"indeed\"],\n",
    "    search_term=\"data analyst\",\n",
    "    location=\"New York\",\n",
    "    results_wanted=300,\n",
    "    country_indeed='USA',\n",
    "    enforce_annual_salary=True,\n",
    "    description_format=\"html\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "ny_jobs['state'] = 'New York'\n",
    "ny_jobs.to_csv('../data/newyork_jobs.csv', index=False)\n",
    "print(f\"\\n New York: {len(ny_jobs)} jobs scraped\")\n",
    "print(f\"Completed at: {datetime.now()}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "842ab0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Texas scrape...\n",
      "Time: 2025-11-17 00:57:16.806693\n",
      "\n",
      " Texas: 300 jobs scraped\n",
      "Completed at: 2025-11-17 00:57:19.187268\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Texas Scrape (Indeed Only)\n",
    "print(\"Starting Texas scrape...\")\n",
    "print(f\"Time: {datetime.now()}\")\n",
    "\n",
    "tx_jobs = scrape_jobs(\n",
    "    site_name=[\"indeed\"],\n",
    "    search_term=\"data analyst\",\n",
    "    location=\"Texas\",\n",
    "    results_wanted=300,\n",
    "    country_indeed='USA',\n",
    "    enforce_annual_salary=True,\n",
    "    description_format=\"html\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "tx_jobs['state'] = 'Texas'\n",
    "tx_jobs.to_csv('../data/texas_jobs.csv', index=False)\n",
    "print(f\"\\n Texas: {len(tx_jobs)} jobs scraped\")\n",
    "print(f\"Completed at: {datetime.now()}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "271a11da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining all state data...\n",
      "\n",
      " Combined data saved!\n",
      "Total jobs: 800\n",
      "  - California: 200\n",
      "  - New York: 300\n",
      "  - Texas: 300\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Combine All Data\n",
    "print(\"Combining all state data...\")\n",
    "\n",
    "# Read all CSVs\n",
    "ca_jobs = pd.read_csv('../data/california_jobs.csv')\n",
    "ny_jobs = pd.read_csv('../data/newyork_jobs.csv')\n",
    "tx_jobs = pd.read_csv('../data/texas_jobs.csv')\n",
    "\n",
    "# Combine\n",
    "all_jobs = pd.concat([ca_jobs, ny_jobs, tx_jobs], ignore_index=True)\n",
    "\n",
    "# Save combined CSV\n",
    "all_jobs.to_csv('../data/all_states_jobs.csv', index=False)\n",
    "\n",
    "print(f\"\\n Combined data saved!\")\n",
    "print(f\"Total jobs: {len(all_jobs)}\")\n",
    "print(f\"  - California: {len(ca_jobs)}\")\n",
    "print(f\"  - New York: {len(ny_jobs)}\")\n",
    "print(f\"  - Texas: {len(tx_jobs)}\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b0ad2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Excel file with separate sheets...\n",
      "\n",
      " Created Excel file: jobs_by_state.xlsx\n",
      "   Sheets:\n",
      "   - California: 200 jobs\n",
      "   - New York: 300 jobs\n",
      "   - Texas: 300 jobs\n",
      "   - All States: 800 jobs\n",
      "\n",
      " All done! Check your /data folder for the files.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Create Excel File with Separate Sheets\n",
    "print(\"Creating Excel file with separate sheets...\")\n",
    "\n",
    "# Key columns to keep\n",
    "columns_to_keep = [\n",
    "    'title', \n",
    "    'company', \n",
    "    'location', \n",
    "    'min_amount', \n",
    "    'max_amount', \n",
    "    'currency',\n",
    "    'interval',\n",
    "    'salary_source',\n",
    "    'date_posted', \n",
    "    'job_type', \n",
    "    'is_remote', \n",
    "    'job_url',\n",
    "    'description'\n",
    "]\n",
    "\n",
    "# Install openpyxl if needed\n",
    "try:\n",
    "    import openpyxl\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    import sys\n",
    "    print(\"Installing openpyxl...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"openpyxl\", \"--break-system-packages\"])\n",
    "    print(\" openpyxl installed!\")\n",
    "\n",
    "# Create Excel writer\n",
    "with pd.ExcelWriter('../data/jobs_by_state.xlsx', engine='openpyxl') as writer:\n",
    "    # Write each state to a separate sheet\n",
    "    ca_jobs[columns_to_keep].to_excel(writer, sheet_name='California', index=False)\n",
    "    ny_jobs[columns_to_keep].to_excel(writer, sheet_name='New York', index=False)\n",
    "    tx_jobs[columns_to_keep].to_excel(writer, sheet_name='Texas', index=False)\n",
    "    \n",
    "    # Add combined sheet with state column\n",
    "    all_with_state = all_jobs[columns_to_keep + ['state']].copy()\n",
    "    all_with_state.to_excel(writer, sheet_name='All States', index=False)\n",
    "\n",
    "print(\"\\n Created Excel file: jobs_by_state.xlsx\")\n",
    "print(\"   Sheets:\")\n",
    "print(\"   - California: {} jobs\".format(len(ca_jobs)))\n",
    "print(\"   - New York: {} jobs\".format(len(ny_jobs)))\n",
    "print(\"   - Texas: {} jobs\".format(len(tx_jobs)))\n",
    "print(\"   - All States: {} jobs\".format(len(all_jobs)))\n",
    "print(\"\\n All done! Check your /data folder for the files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72a55ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating summary report...\n",
      "\n",
      "================================================================================\n",
      "JOB MARKET SUMMARY - Data Analyst Positions\n",
      "================================================================================\n",
      "     State  Total Jobs  Jobs with Salary Avg Min Salary Avg Max Salary  Remote Jobs\n",
      "California         200               173        $94,885       $130,866           45\n",
      "  New York         300               252        $90,240       $121,277           72\n",
      "     Texas         300               143        $90,503       $123,795           59\n",
      "     TOTAL         800               568        $91,721       $124,832          176\n",
      "================================================================================\n",
      "\n",
      " Summary saved to: summary_report.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Create Summary Report\n",
    "print(\"Creating summary report...\")\n",
    "\n",
    "# Calculate summary statistics\n",
    "summary = {\n",
    "    'State': ['California', 'New York', 'Texas', 'TOTAL'],\n",
    "    'Total Jobs': [\n",
    "        len(ca_jobs), \n",
    "        len(ny_jobs), \n",
    "        len(tx_jobs), \n",
    "        len(all_jobs)\n",
    "    ],\n",
    "    'Jobs with Salary': [\n",
    "        ca_jobs['min_amount'].notna().sum(),\n",
    "        ny_jobs['min_amount'].notna().sum(),\n",
    "        tx_jobs['min_amount'].notna().sum(),\n",
    "        all_jobs['min_amount'].notna().sum()\n",
    "    ],\n",
    "    'Avg Min Salary': [\n",
    "        ca_jobs['min_amount'].mean(),\n",
    "        ny_jobs['min_amount'].mean(),\n",
    "        tx_jobs['min_amount'].mean(),\n",
    "        all_jobs['min_amount'].mean()\n",
    "    ],\n",
    "    'Avg Max Salary': [\n",
    "        ca_jobs['max_amount'].mean(),\n",
    "        ny_jobs['max_amount'].mean(),\n",
    "        tx_jobs['max_amount'].mean(),\n",
    "        all_jobs['max_amount'].mean()\n",
    "    ],\n",
    "    'Remote Jobs': [\n",
    "        ca_jobs['is_remote'].sum(),\n",
    "        ny_jobs['is_remote'].sum(),\n",
    "        tx_jobs['is_remote'].sum(),\n",
    "        all_jobs['is_remote'].sum()\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "\n",
    "# Format currency columns\n",
    "for col in ['Avg Min Salary', 'Avg Max Salary']:\n",
    "    summary_df[col] = summary_df[col].apply(\n",
    "        lambda x: f\"${x:,.0f}\" if pd.notna(x) else \"N/A\"\n",
    "    )\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"JOB MARKET SUMMARY - Data Analyst Positions\")\n",
    "print(\"=\" * 80)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv('../data/summary_report.csv', index=False)\n",
    "print(\"\\n Summary saved to: summary_report.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
