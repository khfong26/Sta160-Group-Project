{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "859fa170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pathlib\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aabbcbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\rachi\\OneDrive\\Desktop\\school\\Sta160-Group-Project\\notebooks\n",
      "Data folder: c:\\Users\\rachi\\OneDrive\\Desktop\\school\\Sta160-Group-Project\\notebooks\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = pathlib.Path.cwd()\n",
    "DATA_RAW = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "DATA_RAW.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "GLASSDOOR_BASE = \"https://www.glassdoor.com\"\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Data folder:\", DATA_RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d4512db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_location(location_name, query=\"data analyst\", pages_to_scroll=3, max_jobs=50, filter_location=True):\n",
    "    \"\"\"Scrape Glassdoor for a specific location with full job details\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Scraping: {location_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Add location to query\n",
    "    search_query = f\"{query} {location_name}\"\n",
    "    \n",
    "    # Build URL\n",
    "    url = f\"https://www.glassdoor.com/Job/jobs.htm?sc.keyword={search_query}&locT=S&locKeyword={location_name}\"\n",
    "    print(f\"Opening: {url}\")\n",
    "    \n",
    "    # Start driver\n",
    "    driver = start_driver(headless=False)\n",
    "    driver.get(url)\n",
    "    time.sleep(4)\n",
    "    \n",
    "    # Scroll to load initial jobs\n",
    "    print(\"Scrolling to load jobs...\")\n",
    "    smart_scroll(driver, scrolls=pages_to_scroll)\n",
    "    \n",
    "    # Click \"Show more jobs\" button multiple times to load more jobs\n",
    "    print(\"Loading more jobs...\")\n",
    "    for attempt in range(5):  # Try to click \"Show more jobs\" 5 times\n",
    "        try:\n",
    "            show_more_jobs_btn = driver.find_element(By.XPATH, \"//button[contains(text(), 'Show more jobs')]\")\n",
    "            if show_more_jobs_btn.is_displayed():\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", show_more_jobs_btn)\n",
    "                time.sleep(1)\n",
    "                driver.execute_script(\"arguments[0].click();\", show_more_jobs_btn)\n",
    "                print(f\"  Clicked 'Show more jobs' button ({attempt + 1}/5)\")\n",
    "                time.sleep(3)\n",
    "                # Scroll a bit after clicking\n",
    "                smart_scroll(driver, scrolls=2)\n",
    "        except:\n",
    "            print(f\"  No more 'Show more jobs' button\")\n",
    "            break\n",
    "    \n",
    "    # Find job cards\n",
    "    print(\"\\nLooking for job cards...\")\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    selectors = ['li[data-test=\"jobListing\"]', 'li.JobsList_jobListItem']\n",
    "    \n",
    "    cards = []\n",
    "    for sel in selectors:\n",
    "        try:\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, sel)))\n",
    "            cards = driver.find_elements(By.CSS_SELECTOR, sel)\n",
    "            if cards:\n",
    "                print(f\"✓ Found {len(cards)} total job cards\")\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if not cards:\n",
    "        print(\"❌ No cards found!\")\n",
    "        driver.quit()\n",
    "        return []\n",
    "    \n",
    "    # Limit number of jobs\n",
    "    cards_to_scrape = cards[:max_jobs]\n",
    "    print(f\"Will scrape {len(cards_to_scrape)} jobs\\n\")\n",
    "    \n",
    "    # Parse all cards\n",
    "    jobs_data = []\n",
    "    for i, card in enumerate(cards_to_scrape):\n",
    "        try:\n",
    "            print(f\"[{i+1}/{len(cards_to_scrape)}] \", end='', flush=True)\n",
    "            \n",
    "            # Get basic info from card\n",
    "            card_html = card.get_attribute(\"outerHTML\")\n",
    "            parsed = parse_glassdoor_job_card(card_html)\n",
    "            \n",
    "            if not parsed['title']:\n",
    "                print(\"Skipped (no title)\")\n",
    "                continue\n",
    "            \n",
    "            # Filter by location\n",
    "            if filter_location:\n",
    "                job_location = parsed.get('location', '').lower()\n",
    "                if location_name.lower() == \"california\":\n",
    "                    if 'ca' not in job_location and 'california' not in job_location:\n",
    "                        print(f\"❌ Not CA: {parsed['location']}\")\n",
    "                        continue\n",
    "                elif location_name.lower() == \"new york\":\n",
    "                    if 'ny' not in job_location and 'new york' not in job_location:\n",
    "                        print(f\"❌ Not NY: {parsed['location']}\")\n",
    "                        continue\n",
    "            \n",
    "            print(f\"{parsed['title'][:45]} - \", end='', flush=True)\n",
    "            \n",
    "            # Click the card\n",
    "            try:\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", card)\n",
    "                time.sleep(0.8)\n",
    "                driver.execute_script(\"arguments[0].click();\", card)\n",
    "                time.sleep(3)\n",
    "            except:\n",
    "                print(\"❌ Can't click\")\n",
    "                continue\n",
    "            \n",
    "            # Click \"Show more\" button to expand description\n",
    "            try:\n",
    "                time.sleep(1)\n",
    "                show_btns = driver.find_elements(By.XPATH, \"//button[contains(text(), 'Show more')]\")\n",
    "                for btn in show_btns:\n",
    "                    try:\n",
    "                        if btn.is_displayed():\n",
    "                            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", btn)\n",
    "                            time.sleep(0.5)\n",
    "                            driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                            time.sleep(2)\n",
    "                            print(\"expanded - \", end='', flush=True)\n",
    "                            break\n",
    "                    except:\n",
    "                        continue\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Get full job description\n",
    "            try:\n",
    "                full_text = \"\"\n",
    "                \n",
    "                # Try to get the job description\n",
    "                try:\n",
    "                    job_panel = driver.find_element(By.CSS_SELECTOR, 'div[class*=\"JobDetails\"]')\n",
    "                    full_text = job_panel.text\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                if not full_text or len(full_text) < 100:\n",
    "                    try:\n",
    "                        right_panel = driver.find_element(By.XPATH, \"//div[contains(@class, 'JobDetails')]\")\n",
    "                        full_text = right_panel.text\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                if not full_text or len(full_text) < 50:\n",
    "                    print(\"⚠️ No description\")\n",
    "                    parsed['job_description'] = None\n",
    "                    parsed['requirements'] = None\n",
    "                    parsed['benefits'] = None\n",
    "                    parsed['responsibilities'] = None\n",
    "                    parsed['qualifications'] = None\n",
    "                    parsed['skills_mentioned'] = []\n",
    "                else:\n",
    "                    parsed['job_description'] = full_text\n",
    "                    \n",
    "                    # Extract sections\n",
    "                    lines = full_text.split('\\n')\n",
    "                    \n",
    "                    requirements = []\n",
    "                    benefits = []\n",
    "                    responsibilities = []\n",
    "                    qualifications = []\n",
    "                    \n",
    "                    current_section = None\n",
    "                    \n",
    "                    for line in lines:\n",
    "                        line_stripped = line.strip()\n",
    "                        if not line_stripped:\n",
    "                            continue\n",
    "                        \n",
    "                        line_lower = line_stripped.lower()\n",
    "                        \n",
    "                        # Detect section headers\n",
    "                        if any(kw in line_lower for kw in ['requirements:', 'required qualifications:', 'minimum qualifications:', 'what you need:', 'what you will need:']):\n",
    "                            current_section = 'requirements'\n",
    "                            continue\n",
    "                        elif any(kw in line_lower for kw in ['qualifications:', 'preferred qualifications:', 'nice to have:', 'preferred skills:', 'preferred:']):\n",
    "                            current_section = 'qualifications'\n",
    "                            continue\n",
    "                        elif any(kw in line_lower for kw in ['responsibilities:', 'what you will do:', 'duties:', 'the position:', 'your role:']):\n",
    "                            current_section = 'responsibilities'\n",
    "                            continue\n",
    "                        elif any(kw in line_lower for kw in ['benefits:', 'what we offer:', 'perks:', 'compensation:', 'why join']):\n",
    "                            current_section = 'benefits'\n",
    "                            continue\n",
    "                        elif any(kw in line_lower for kw in ['about us', 'about the company', 'about', 'the department']):\n",
    "                            current_section = None\n",
    "                            continue\n",
    "                        \n",
    "                        # Add content to current section\n",
    "                        if current_section == 'requirements' and len(line_stripped) > 10:\n",
    "                            requirements.append(line_stripped)\n",
    "                        elif current_section == 'qualifications' and len(line_stripped) > 10:\n",
    "                            qualifications.append(line_stripped)\n",
    "                        elif current_section == 'responsibilities' and len(line_stripped) > 10:\n",
    "                            responsibilities.append(line_stripped)\n",
    "                        elif current_section == 'benefits' and len(line_stripped) > 10:\n",
    "                            benefits.append(line_stripped)\n",
    "                    \n",
    "                    # Store sections\n",
    "                    parsed['requirements'] = '\\n'.join(requirements[:20]) if requirements else None\n",
    "                    parsed['qualifications'] = '\\n'.join(qualifications[:20]) if qualifications else None\n",
    "                    parsed['responsibilities'] = '\\n'.join(responsibilities[:20]) if responsibilities else None\n",
    "                    parsed['benefits'] = '\\n'.join(benefits[:15]) if benefits else None\n",
    "                    \n",
    "                    # Extract skills\n",
    "                    skills = []\n",
    "                    skill_keywords = ['python', 'sql', 'excel', 'tableau', 'power bi', \n",
    "                                    'statistics', 'machine learning', 'aws', 'azure', 'pandas']\n",
    "                    \n",
    "                    full_lower = full_text.lower()\n",
    "                    for skill in skill_keywords:\n",
    "                        if skill in full_lower:\n",
    "                            skills.append(skill.title())\n",
    "                    \n",
    "                    parsed['skills_mentioned'] = list(set(skills))\n",
    "                    \n",
    "                    sections_found = []\n",
    "                    if requirements:\n",
    "                        sections_found.append('req')\n",
    "                    if qualifications:\n",
    "                        sections_found.append('qual')\n",
    "                    if responsibilities:\n",
    "                        sections_found.append('resp')\n",
    "                    if benefits:\n",
    "                        sections_found.append('ben')\n",
    "                    \n",
    "                    if sections_found:\n",
    "                        print(f\"✓ [{','.join(sections_found)}]\")\n",
    "                    else:\n",
    "                        print(f\"✓ {len(full_text)} chars\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error: {str(e)[:40]}\")\n",
    "                parsed['job_description'] = None\n",
    "                parsed['requirements'] = None\n",
    "                parsed['qualifications'] = None\n",
    "                parsed['responsibilities'] = None\n",
    "                parsed['benefits'] = None\n",
    "                parsed['skills_mentioned'] = []\n",
    "            \n",
    "            # Add metadata\n",
    "            parsed['location_category'] = location_name\n",
    "            parsed['scrape_date'] = datetime.now().isoformat()\n",
    "            parsed['source'] = 'glassdoor'\n",
    "            \n",
    "            jobs_data.append(parsed)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {str(e)[:50]}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"✓ Scraped {len(jobs_data)} jobs from {location_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    driver.quit()\n",
    "    return jobs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d3f7633d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Scraping: California\n",
      "============================================================\n",
      "\n",
      "Opening: https://www.glassdoor.com/Job/jobs.htm?sc.keyword=data analyst California&locT=S&locKeyword=California\n",
      "Scrolling to load jobs...\n",
      "Loading more jobs...\n",
      "  No more 'Show more jobs' button\n",
      "\n",
      "Looking for job cards...\n",
      "✓ Found 30 total job cards\n",
      "Will scrape 30 jobs\n",
      "\n",
      "[1/30] ❌ Not CA: Baltimore, MD\n",
      "[2/30] ❌ Not CA: Farmington Hills, MI\n",
      "[3/30] ❌ Not CA: Arlington, VA\n",
      "[4/30] Board Certified Behavior Analyst (BCBA) – Cen - ✓ 2836 chars\n",
      "[5/30] Associate Data Analyst - ✓ 2836 chars\n",
      "[6/30] Clinical Supervisor, BCBA - ✓ 2836 chars\n",
      "[7/30] ❌ Not CA: Baltimore, MD\n",
      "[8/30] Research Data Analyst - ✓ 2836 chars\n",
      "[9/30] Data Analyst - ✓ 2836 chars\n",
      "[10/30] ❌ Not CA: United States\n",
      "[11/30] ❌ Not CA: New York, NY\n",
      "[12/30] Clinical Supervisor, BCBA - ✓ 2836 chars\n",
      "[13/30] Board Certified Behavior Analyst (BCBA) - Cen - ✓ 2836 chars\n",
      "[14/30] Clinical Supervisor, BCBA - ✓ 2836 chars\n",
      "[15/30] Board Certified Behavior Analyst (BCBA) - Cen - ✓ 2836 chars\n",
      "[16/30] Senior Behavior Analyst (BCBA) - ✓ 2836 chars\n",
      "[17/30] ❌ Not CA: Atlanta, GA\n",
      "[18/30] Research Data Analyst - ✓ 2836 chars\n",
      "[19/30] Data Analyst - ✓ 2836 chars\n",
      "[20/30] Data Manager/Analyst - ✓ 2836 chars\n",
      "[21/30] Data Analyst II, Powertrain Data & Automation - ✓ 2836 chars\n",
      "[22/30] ❌ Not CA: Grapevine, TX\n",
      "[23/30] FP&A Manager - Commercial Sales - ✓ 2836 chars\n",
      "[24/30] Business Data Analyst (remote possible) - ✓ 2836 chars\n",
      "[25/30] Data Analyst - ✓ 2836 chars\n",
      "[26/30] ❌ Not CA: Minneapolis, MN\n",
      "[27/30] Data & Performance Analyst - ✓ 2836 chars\n",
      "[28/30] Data Analyst (Business Intelligence) - ✓ 2836 chars\n",
      "[29/30] ❌ Not CA: Cincinnati, OH\n",
      "[30/30] Data Management (DM) Analyst I - ❌ Can't click\n",
      "\n",
      "============================================================\n",
      "✓ Scraped 19 jobs from California\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "california_jobs = scrape_location(\"California\", query=\"data analyst\", pages_to_scroll=3, max_jobs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4fc0cc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 19 California jobs to: c:\\Users\\rachi\\OneDrive\\Desktop\\school\\Sta160-Group-Project\\notebooks\\data\\raw\\glassdoor_jobs_california.json\n"
     ]
    }
   ],
   "source": [
    "ca_file = DATA_RAW / \"glassdoor_jobs_california.json\"\n",
    "with open(ca_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(california_jobs, f, indent=2)\n",
    "\n",
    "print(f\"Saved {len(california_jobs)} California jobs to: {ca_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
