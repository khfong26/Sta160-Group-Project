{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "859fa170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pathlib\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aabbcbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\rachi\\OneDrive\\Desktop\\school\\Sta160-Group-Project\\notebooks\n",
      "Data folder: c:\\Users\\rachi\\OneDrive\\Desktop\\school\\Sta160-Group-Project\\notebooks\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = pathlib.Path.cwd()\n",
    "DATA_RAW = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "DATA_RAW.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "GLASSDOOR_BASE = \"https://www.glassdoor.com\"\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Data folder:\", DATA_RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "084fca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_driver(headless=False):\n",
    "    \"\"\"Initialize Chrome driver\"\"\"\n",
    "    opts = Options()\n",
    "    if headless:\n",
    "        opts.add_argument(\"--headless=new\")\n",
    "        opts.add_argument(\"--disable-gpu\")\n",
    "    opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    opts.add_argument(\"--start-maximized\")\n",
    "    opts.add_argument(\"--window-size=1280,1000\")\n",
    "    \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)\n",
    "    return driver\n",
    "\n",
    "def smart_scroll(driver, scrolls=3, pause_min=1.0, pause_max=2.0):\n",
    "    \"\"\"Scroll down the page to load lazy content\"\"\"\n",
    "    body = driver.find_element(By.TAG_NAME, \"body\")\n",
    "    for i in range(scrolls):\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(random.uniform(pause_min, pause_max))\n",
    "        driver.execute_script(\"window.scrollBy(0, 300);\")\n",
    "        time.sleep(random.uniform(0.5, 1.0))\n",
    "    time.sleep(random.uniform(pause_min, pause_max))\n",
    "\n",
    "def parse_glassdoor_job_card(html: str):\n",
    "    \"\"\"Parse a single Glassdoor job card HTML\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    # Title\n",
    "    title = None\n",
    "    title_tag = soup.find('a', {'data-test': 'job-title'})\n",
    "    if title_tag:\n",
    "        title = title_tag.get_text(strip=True)\n",
    "    \n",
    "    # Company\n",
    "    company = None\n",
    "    company_tag = soup.find('div', {'data-test': 'employer-name'})\n",
    "    if not company_tag:\n",
    "        company_tag = soup.find('div', class_=lambda x: x and 'EmployerProfile' in x)\n",
    "    if company_tag:\n",
    "        company = company_tag.get_text(strip=True)\n",
    "    \n",
    "    # Location\n",
    "    location = None\n",
    "    loc_tag = soup.find('div', {'data-test': 'emp-location'})\n",
    "    if loc_tag:\n",
    "        location = loc_tag.get_text(strip=True)\n",
    "    \n",
    "    # Salary\n",
    "    salary = None\n",
    "    salary_tag = soup.find('div', {'data-test': 'detailSalary'})\n",
    "    if salary_tag:\n",
    "        salary = salary_tag.get_text(strip=True)\n",
    "    \n",
    "    # URL\n",
    "    job_url = None\n",
    "    link_tag = soup.find('a', {'data-test': 'job-title'})\n",
    "    if link_tag and link_tag.get('href'):\n",
    "        job_url = urljoin(GLASSDOOR_BASE, link_tag['href'])\n",
    "    \n",
    "    # Attributes\n",
    "    attributes = []\n",
    "    rating_tag = soup.find('span', {'data-test': 'rating'})\n",
    "    if rating_tag:\n",
    "        attributes.append(f\"Rating: {rating_tag.get_text(strip=True)}\")\n",
    "    date_tag = soup.find('div', {'data-test': 'job-age'})\n",
    "    if date_tag:\n",
    "        attributes.append(f\"Posted: {date_tag.get_text(strip=True)}\")\n",
    "    \n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"company\": company,\n",
    "        \"location\": location,\n",
    "        \"salary\": salary,\n",
    "        \"url\": job_url,\n",
    "        \"attributes\": attributes,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5664347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_location(location_name, query=\"data analyst\", pages_to_scroll=3):\n",
    "    \"\"\"Scrape Glassdoor for a specific location\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Scraping: {location_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Build URL\n",
    "    url = f\"https://www.glassdoor.com/Job/jobs.htm?sc.keyword={query}&locT=S&locKeyword={location_name}\"\n",
    "    print(f\"Opening: {url}\")\n",
    "    \n",
    "    # Start driver\n",
    "    driver = start_driver(headless=False)\n",
    "    driver.get(url)\n",
    "    time.sleep(2 + random.random()*1.5)\n",
    "    \n",
    "    # Scroll to load more jobs\n",
    "    print(\"Scrolling to load jobs...\")\n",
    "    smart_scroll(driver, scrolls=pages_to_scroll)\n",
    "    \n",
    "    # Find job cards\n",
    "    print(\"Looking for job cards...\")\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    selectors = ['li[data-test=\"jobListing\"]', 'li.JobsList_jobListItem', 'div.JobCard']\n",
    "    \n",
    "    cards = []\n",
    "    for sel in selectors:\n",
    "        try:\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, sel)))\n",
    "            cards = driver.find_elements(By.CSS_SELECTOR, sel)\n",
    "            if cards:\n",
    "                print(f\" Found {len(cards)} cards using '{sel}'\")\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if not cards:\n",
    "        print(\" No cards found!\")\n",
    "        driver.quit()\n",
    "        return []\n",
    "    \n",
    "    # Extract HTML\n",
    "    print(\"Extracting job data...\")\n",
    "    cards_html = []\n",
    "    for i, c in enumerate(cards):\n",
    "        try:\n",
    "            html = c.get_attribute(\"outerHTML\")\n",
    "            cards_html.append(html)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error on card {i}: {e}\")\n",
    "    \n",
    "    # Parse all cards\n",
    "    jobs_data = []\n",
    "    for html in cards_html:\n",
    "        parsed = parse_glassdoor_job_card(html)\n",
    "        if parsed['title']:  # Only add if we got a title\n",
    "            parsed['location_category'] = location_name\n",
    "            parsed['scrape_date'] = datetime.now().isoformat()\n",
    "            parsed['source'] = 'glassdoor'\n",
    "            jobs_data.append(parsed)\n",
    "    \n",
    "    print(f\"âœ“ Parsed {len(jobs_data)} jobs\")\n",
    "    \n",
    "    # Show first 3\n",
    "    print(f\"\\nFirst 3 jobs:\")\n",
    "    for i, job in enumerate(jobs_data[:3]):\n",
    "        print(f\"  {i+1}. {job['title']} at {job['company']}\")\n",
    "        if job['salary']:\n",
    "            print(f\"      {job['salary']}\")\n",
    "    \n",
    "    # Close browser\n",
    "    driver.quit()\n",
    "    print(f\"\\nâœ“ Browser closed for {location_name}\")\n",
    "    \n",
    "    return jobs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65ae3420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Scraping: California\n",
      "============================================================\n",
      "\n",
      "Opening: https://www.glassdoor.com/Job/jobs.htm?sc.keyword=data analyst&locT=S&locKeyword=California\n",
      "Scrolling to load jobs...\n",
      "Looking for job cards...\n",
      "âœ“ Found 30 cards using 'li[data-test=\"jobListing\"]'\n",
      "Extracting job data...\n",
      "âœ“ Parsed 30 jobs\n",
      "\n",
      "First 3 jobs:\n",
      "  1. Data Analyst, Specialist at Vanguard3.7\n",
      "     ðŸ’° $62K - $90K(Glassdoor est.)\n",
      "  2. Sr Business Analyst at Ajinomoto Foods North America3.9\n",
      "     ðŸ’° $120K - $130K(Employer provided)\n",
      "  3. People Data Analyst at Central Health3.4\n",
      "     ðŸ’° $53K - $77K(Glassdoor est.)\n",
      "\n",
      "âœ“ Browser closed for California\n"
     ]
    }
   ],
   "source": [
    "california_jobs = scrape_location(\"California\", query=\"data analyst\", pages_to_scroll=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fc0cc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 30 California jobs to: c:\\Users\\rachi\\OneDrive\\Desktop\\school\\Sta160-Group-Project\\notebooks\\data\\raw\\glassdoor_jobs_california.json\n"
     ]
    }
   ],
   "source": [
    "ca_file = DATA_RAW / \"glassdoor_jobs_california.json\"\n",
    "with open(ca_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(california_jobs, f, indent=2)\n",
    "\n",
    "print(f\"Saved {len(california_jobs)} California jobs to: {ca_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
